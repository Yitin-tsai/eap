server:
  port: 8084

spring:
  application:
    name: eap-ai-client
  
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        options:
          model: llama3.1
          temperature: 0.7
          top-p: 0.9
          max-tokens: 1000
      connect-timeout: PT1M
      read-timeout: PT10M

eap:
  mcp:
    base-url: http://localhost:8083
    base-path: ""         
    sse-path: /mcp/sse
    message-path: /mcp/message
    timeout-seconds: 60

logging:
  level:
    com.eap.ai: DEBUG
    org.springframework.ai: DEBUG
    org.springframework.ai.ollama: DEBUG
    org.springframework.web.reactive.function.client.ExchangeFunctions: TRACE
    reactor.netty.http.client: DEBUG
    reactor.netty.transport: DEBUG
  pattern:
    console: "%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics
  endpoint:
    health:
      show-details: always
